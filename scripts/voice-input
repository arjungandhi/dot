#!/usr/bin/env python3
"""
Voice-to-text input using Faster Whisper.
Hold-to-record: records while running, transcribes live with streaming output.
Updates status file for waybar integration.

Usage:
    voice-input start    # Start recording with live transcription
    voice-input stop     # Stop recording
    voice-input toggle   # Toggle recording on/off
    voice-input init     # Initialize status file
    voice-input          # Run recording (same as start but foreground)
"""

import sys
import os
import tempfile
import subprocess
import signal
import time
import threading
import queue

# Lazy imports for heavy libraries - only import when needed
# This significantly speeds up start/stop commands

# Configuration
SAMPLE_RATE = 16000
CHANNELS = 1
MODEL_SIZE = "base"  # Options: tiny, base, small, medium, large-v2, large-v3
STATUS_FILE = "/tmp/voice-input-status"
PID_FILE = "/tmp/voice-input.pid"
CACHE_DIR = os.path.expanduser("~/.cache/voice-input")

# Streaming configuration
CHUNK_DURATION = 1.0  # Process audio every 1 second
BUFFER_DURATION = 3.0  # Keep 3 seconds of audio for context

# Auto-enter configuration: window titles/classes that should auto-submit
AUTO_ENTER_PATTERNS = [
    "com.mitchellh.ghostty",  # Ghostty terminal (where Claude Code runs)
]

# Global variables for signal handling and streaming
recording_data = []
stream = None
stop_recording = False
transcription_queue = queue.Queue()
last_transcription = ""
whisper_model = None

def update_status(status, text=""):
    """Update status file for waybar."""
    os.makedirs(os.path.dirname(STATUS_FILE), exist_ok=True)

    status_icons = {
        "idle": "󰍬",      # microphone icon
        "recording": "󰑊", # recording icon
        "transcribing": "󰔟", # loading/processing icon
        "typing": "󰗧",    # keyboard icon
        "error": "󰅖"      # error/x icon
    }

    icon = status_icons.get(status, "")

    with open(STATUS_FILE, 'w') as f:
        if text:
            f.write(f'{{"text": "{icon}", "tooltip": "{text}", "class": "{status}"}}')
        else:
            f.write(f'{{"text": "{icon}", "class": "{status}"}}')

def init():
    """Initialize voice input status file."""
    update_status("idle")
    print("Voice input initialized", file=sys.stderr)

def start():
    """Start recording in background."""
    # Check if already recording
    if os.path.exists(PID_FILE):
        print("Already recording", file=sys.stderr)
        return

    # Kill any zombie processes
    subprocess.run(["pkill", "-9", "voice-input"], stderr=subprocess.DEVNULL)

    # Pre-load audio libraries in main process to speed up recording start
    # This ensures the background process can start recording immediately
    try:
        import sounddevice as sd
        import numpy as np
        from scipy.io import wavfile
    except ImportError:
        pass  # Libraries will be imported in background process if not available

    # Start in background
    proc = subprocess.Popen([sys.executable, __file__],
                           stdout=subprocess.DEVNULL,
                           stderr=subprocess.DEVNULL)

    # Save PID
    with open(PID_FILE, 'w') as f:
        f.write(str(proc.pid))

    print(f"Recording started (PID: {proc.pid})", file=sys.stderr)

def stop():
    """Stop recording and transcribe."""
    if os.path.exists(PID_FILE):
        with open(PID_FILE, 'r') as f:
            pid = int(f.read().strip())

        try:
            os.kill(pid, signal.SIGTERM)
            print(f"Stopped recording (PID: {pid})", file=sys.stderr)
        except ProcessLookupError:
            print("No recording process found", file=sys.stderr)

        # Clean up PID file
        os.remove(PID_FILE)
    else:
        print("No active recording", file=sys.stderr)

def toggle():
    """Toggle recording on/off."""
    if os.path.exists(PID_FILE):
        # Currently recording, stop it
        stop()
    else:
        # Not recording, start it
        start()

def audio_callback(indata, frames, time_info, status):
    """Callback for continuous audio recording."""
    if status:
        print(f"Audio callback status: {status}", file=sys.stderr)
    recording_data.append(indata.copy())

def signal_handler(signum, frame):
    """Handle termination signals to stop recording gracefully."""
    global stop_recording, stream
    stop_recording = True
    if stream:
        stream.stop()
        stream.close()

def get_whisper_model():
    """Get or create Whisper model (cached globally)."""
    global whisper_model
    if whisper_model is None:
        from faster_whisper import WhisperModel
        print("Loading Whisper model...", file=sys.stderr)
        os.makedirs(CACHE_DIR, exist_ok=True)
        whisper_model = WhisperModel(
            MODEL_SIZE,
            device="cpu",
            compute_type="int8",
            download_root=CACHE_DIR
        )
    return whisper_model

def transcribe_audio(audio_path):
    """Transcribe audio file using Faster Whisper."""
    model = get_whisper_model()
    segments, info = model.transcribe(audio_path, beam_size=5)
    transcription = " ".join([segment.text for segment in segments])
    return transcription.strip()

def transcribe_audio_data(audio_data, sample_rate=SAMPLE_RATE):
    """Transcribe audio data (numpy array) using Faster Whisper."""
    import numpy as np
    from scipy.io import wavfile

    # Save to temporary file
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio:
        temp_path = temp_audio.name

    wavfile.write(temp_path, sample_rate, audio_data)

    try:
        transcription = transcribe_audio(temp_path)
        return transcription
    finally:
        os.unlink(temp_path)

def should_auto_enter():
    """Check if we should auto-press Enter based on active window context."""
    try:
        import json
        result = subprocess.run(
            ["hyprctl", "activewindow", "-j"],
            capture_output=True,
            text=True,
            check=True
        )
        window_info = json.loads(result.stdout)

        window_class = window_info.get("class", "").lower()
        window_title = window_info.get("title", "").lower()

        # Check if any pattern matches the window class or title
        for pattern in AUTO_ENTER_PATTERNS:
            if pattern.lower() in window_class or pattern.lower() in window_title:
                print(f"Auto-enter triggered for window: {window_class} / {window_title}", file=sys.stderr)
                return True

        return False
    except Exception as e:
        print(f"Error checking window context: {e}", file=sys.stderr)
        return False

def type_text(text):
    """Type the text using wtype (Wayland)."""
    if not text:
        print("No text to type!", file=sys.stderr)
        return

    print(f"Typing: {text}", file=sys.stderr)
    subprocess.run(["wtype", text], check=True)

    # Auto-press Enter if in matching context
    if should_auto_enter():
        print("Pressing Enter...", file=sys.stderr)
        subprocess.run(["wtype", "-k", "Return"], check=True)

def type_text_incremental(new_text, previous_text=""):
    """Type only the new part of text that wasn't in previous_text."""
    if not new_text:
        return

    # Find the common prefix
    if previous_text and new_text.startswith(previous_text):
        # Type only the new part
        new_part = new_text[len(previous_text):]
        if new_part:
            # Add space if needed (if previous text didn't end with space)
            if previous_text and not previous_text.endswith(" ") and not new_part.startswith(" "):
                new_part = " " + new_part
            print(f"Typing (incremental): {new_part}", file=sys.stderr)
            subprocess.run(["wtype", new_part], check=True)
    else:
        # Transcription changed completely, type the whole thing
        # This shouldn't happen often but handle it gracefully
        print(f"Typing (full): {new_text}", file=sys.stderr)
        subprocess.run(["wtype", new_text], check=True)

def transcription_worker():
    """Worker thread that processes audio chunks and transcribes them."""
    import numpy as np
    global last_transcription, recording_data

    # Pre-load the model in this thread
    get_whisper_model()

    last_typed = ""
    chunk_samples = int(SAMPLE_RATE * CHUNK_DURATION)
    buffer_samples = int(SAMPLE_RATE * BUFFER_DURATION)

    print("Transcription worker started", file=sys.stderr)

    while not stop_recording or len(recording_data) > 0:
        try:
            # Wait a bit before processing
            time.sleep(CHUNK_DURATION)

            if len(recording_data) == 0:
                continue

            # Get current audio buffer
            audio_data = np.concatenate(recording_data, axis=0)

            # Skip if too short (need at least 0.5 seconds)
            if len(audio_data) < SAMPLE_RATE * 0.5:
                continue

            # Use only the most recent buffer_samples for context
            if len(audio_data) > buffer_samples:
                audio_chunk = audio_data[-buffer_samples:]
            else:
                audio_chunk = audio_data

            # Transcribe this chunk
            transcription = transcribe_audio_data(audio_chunk)

            if transcription:
                # Type only the new part
                if transcription != last_typed:
                    # Clean up transcription (remove trailing ellipsis if present)
                    transcription = transcription.strip()
                    if transcription.endswith('...'):
                        transcription = transcription[:-3].rstrip()

                    if not transcription:
                        continue

                    print(f"Raw transcription: '{transcription}'", file=sys.stderr)
                    update_status("typing", f"{transcription[:50]}...")
                    type_text_incremental(transcription, last_typed)
                    last_typed = transcription
                    last_transcription = transcription

        except Exception as e:
            print(f"Transcription error: {e}", file=sys.stderr)
            import traceback
            traceback.print_exc()

    print("Transcription worker finished", file=sys.stderr)

def record():
    """Main recording function with live streaming transcription."""
    # Import audio libraries first - these are fast
    import sounddevice as sd
    import numpy as np

    global recording_data, stream, stop_recording, last_transcription

    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    try:
        # Reset state
        recording_data = []
        stop_recording = False
        last_transcription = ""

        # Start recording stream
        stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.int16,
            callback=audio_callback
        )

        stream.start()
        print("Recording started with live transcription...", file=sys.stderr)
        update_status("recording", "Recording with live transcription...")

        # Start transcription worker thread
        transcription_thread = threading.Thread(target=transcription_worker, daemon=True)
        transcription_thread.start()

        # Wait for stop signal
        while not stop_recording:
            time.sleep(0.1)

        print("Stop signal received, finishing transcription...", file=sys.stderr)

        # Stop recording
        stream.stop()
        stream.close()

        # Wait for transcription thread to finish processing remaining audio
        transcription_thread.join(timeout=5.0)

        # Press Enter if configured
        if last_transcription and should_auto_enter():
            print("Pressing Enter...", file=sys.stderr)
            subprocess.run(["wtype", "-k", "Return"], check=True)

        update_status("idle")
        print(f"Final transcription: {last_transcription}", file=sys.stderr)

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        update_status("error", str(e))
        sys.exit(1)

def main():
    if len(sys.argv) > 1:
        command = sys.argv[1]
        if command == "init":
            init()
        elif command == "start":
            start()
        elif command == "stop":
            stop()
        elif command == "toggle":
            toggle()
        else:
            print(f"Unknown command: {command}", file=sys.stderr)
            print("Usage: voice-input [init|start|stop|toggle]", file=sys.stderr)
            sys.exit(1)
    else:
        # No command given, run recording
        record()

if __name__ == "__main__":
    main()
