#!/usr/bin/env python3
"""
Voice-to-text input script using Faster Whisper.
Hold-to-record pattern: records while running, transcribes when stopped.
Updates status file for waybar integration.
"""

import sys
import os
import tempfile
import subprocess
import sounddevice as sd
import numpy as np
from faster_whisper import WhisperModel
from scipy.io import wavfile
import signal
import time

# Configuration
SAMPLE_RATE = 16000  # Whisper expects 16kHz
CHANNELS = 1
MODEL_SIZE = "base"  # Options: tiny, base, small, medium, large-v2, large-v3
STATUS_FILE = "/tmp/voice-input-status"
CACHE_DIR = os.path.expanduser("~/.cache/voice-input")

# Global variables for signal handling
recording_data = []
stream = None
stop_recording = False

def update_status(status, text=""):
    """Update status file for waybar."""
    os.makedirs(os.path.dirname(STATUS_FILE), exist_ok=True)

    status_icons = {
        "idle": "üéôÔ∏è",
        "recording": "üé§",
        "transcribing": "‚è≥",
        "typing": "‚å®Ô∏è",
        "error": "‚ùå"
    }

    icon = status_icons.get(status, "")

    with open(STATUS_FILE, 'w') as f:
        if text:
            f.write(f'{{"text": "{icon}", "tooltip": "{text}", "class": "{status}"}}')
        else:
            f.write(f'{{"text": "{icon}", "class": "{status}"}}')

def audio_callback(indata, frames, time_info, status):
    """Callback for continuous audio recording."""
    if status:
        print(f"Audio callback status: {status}", file=sys.stderr)
    recording_data.append(indata.copy())

def signal_handler(signum, frame):
    """Handle termination signals to stop recording gracefully."""
    global stop_recording, stream
    stop_recording = True
    if stream:
        stream.stop()
        stream.close()

def transcribe_audio(audio_path, model_size=MODEL_SIZE):
    """Transcribe audio file using Faster Whisper."""
    print("Loading Whisper model...", file=sys.stderr)

    # Create cache directory if it doesn't exist
    os.makedirs(CACHE_DIR, exist_ok=True)

    # Initialize model (downloads on first run, caches afterward)
    model = WhisperModel(
        model_size,
        device="cpu",
        compute_type="int8",
        download_root=CACHE_DIR
    )

    print("Transcribing...", file=sys.stderr)
    segments, info = model.transcribe(audio_path, beam_size=5)

    # Combine all segments
    transcription = " ".join([segment.text for segment in segments])
    return transcription.strip()

def type_text(text):
    """Type the text using wtype (Wayland)."""
    if not text:
        print("No text to type!", file=sys.stderr)
        return

    print(f"Typing: {text}", file=sys.stderr)
    subprocess.run(["wtype", text], check=True)

def main():
    global recording_data, stream, stop_recording

    # Set up signal handlers
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    try:
        # Start recording
        print("Recording... (will stop when process is killed)", file=sys.stderr)
        update_status("recording", "Recording audio...")

        recording_data = []

        # Open audio stream
        stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.int16,
            callback=audio_callback
        )

        stream.start()

        # Keep recording until signal received
        while not stop_recording:
            time.sleep(0.1)

        # Stop stream
        stream.stop()
        stream.close()

        # Check if we recorded anything
        if not recording_data:
            print("No audio recorded!", file=sys.stderr)
            update_status("idle")
            return

        # Combine all recorded chunks
        audio_data = np.concatenate(recording_data, axis=0)

        # Skip if recording is too short (less than 0.5 seconds)
        if len(audio_data) < SAMPLE_RATE * 0.5:
            print("Recording too short, skipping.", file=sys.stderr)
            update_status("idle")
            return

        # Save to temporary file
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio:
            temp_path = temp_audio.name

        wavfile.write(temp_path, SAMPLE_RATE, audio_data)

        # Transcribe
        update_status("transcribing", "Transcribing audio...")
        text = transcribe_audio(temp_path)

        # Clean up temp file
        os.unlink(temp_path)

        # Type the transcribed text
        if text:
            update_status("typing", f"Typing: {text[:50]}...")
            type_text(text)
            print(f"Transcribed and typed: {text}", file=sys.stderr)
        else:
            print("No speech detected!", file=sys.stderr)

        # Reset to idle
        update_status("idle")

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        update_status("error", str(e))
        sys.exit(1)

if __name__ == "__main__":
    main()
